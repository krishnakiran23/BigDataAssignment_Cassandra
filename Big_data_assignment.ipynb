{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JbOCXah-sXoW",
        "outputId": "4229fd66-bf0c-48aa-81a8-4214c7e74a2b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n"
          ]
        }
      ],
      "source": [
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "import json\n",
        "\n",
        "# This secure connect bundle is autogenerated when you download your SCB,\n",
        "# if yours is different update the file name below\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect()\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install cassandra-driver"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wlv8nUH5spGY",
        "outputId": "0be72b50-4308-42f4-d5e6-2b71c6dbb275"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting cassandra-driver\n",
            "  Downloading cassandra_driver-3.29.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Collecting geomet<0.3,>=0.1 (from cassandra-driver)\n",
            "  Downloading geomet-0.2.1.post1-py3-none-any.whl.metadata (1.0 kB)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (8.1.7)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from geomet<0.3,>=0.1->cassandra-driver) (1.16.0)\n",
            "Downloading cassandra_driver-3.29.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.9/3.9 MB\u001b[0m \u001b[31m32.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading geomet-0.2.1.post1-py3-none-any.whl (18 kB)\n",
            "Installing collected packages: geomet, cassandra-driver\n",
            "Successfully installed cassandra-driver-3.29.2 geomet-0.2.1.post1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import cassandra\n",
        "print(cassandra.__version__)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pKC0m76ps02Z",
        "outputId": "c8d3eb06-55f6-4f55-bff4-4c53c2dc3d3c"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.29.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "_x1MWy7Ttjn-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mZG7zaQUurQ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect('sales_data')\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# Step 2: Load the CSV data using pandas\n",
        "csv_url = 'sales_100.csv'\n",
        "data = pd.read_csv(csv_url)\n",
        "\n",
        "# Step 3: Insert data into the Bronze table\n",
        "insert_query = \"\"\"\n",
        "    INSERT INTO bronze_sales (Region, Country, Item_Type, Sales_Channel, Order_Priority, Order_Date,\n",
        "                              Order_ID, Ship_Date, Units_Sold, Unit_Price, Unit_Cost, Total_Revenue,\n",
        "                              Total_Cost, Total_Profit)\n",
        "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
        "\"\"\"\n",
        "\n",
        "# Loop through the dataframe and insert each row into the Cassandra table\n",
        "for _, row in data.iterrows():\n",
        "    session.execute(insert_query, (row['Region'], row['Country'], row['Item Type'], row['Sales Channel'],\n",
        "                                   row['Order Priority'], row['Order Date'], row['Order ID'], row['Ship Date'],\n",
        "                                   row['UnitsSold'], row['UnitPrice'], row['UnitCost'], row['TotalRevenue'],\n",
        "                                   row['TotalCost'], row['TotalProfit']))\n",
        "\n",
        "print(\"Data inserted into the Bronze table.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 438
        },
        "id": "LpZiTIOqurTS",
        "outputId": "ed101a03-503a-49fe-a80b-43fdc638b770"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00694036-11ec-39fb-8238-d79afd9b0e46. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00694036-11ec-39fb-8238-d79afd9b0e46. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00694036-11ec-39fb-8238-d79afd9b0e46. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InvalidRequest",
          "evalue": "Error from server: code=2200 [Invalid query] message=\"Unable to coerce '7/27/2012' to a formatted date (long)\"",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInvalidRequest\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-a163de260185>\u001b[0m in \u001b[0;36m<cell line: 46>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[0;31m# Loop through the dataframe and insert each row into the Cassandra table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miterrows\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m     session.execute(insert_query, (row['Region'], row['Country'], row['Item Type'], row['Sales Channel'],\n\u001b[0m\u001b[1;32m     48\u001b[0m                                    \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Order Priority'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Order Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Order ID'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'Ship Date'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     49\u001b[0m                                    \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UnitsSold'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UnitPrice'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'UnitCost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'TotalRevenue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.Session.execute\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/cassandra/cluster.cpython-310-x86_64-linux-gnu.so\u001b[0m in \u001b[0;36mcassandra.cluster.ResponseFuture.result\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mInvalidRequest\u001b[0m: Error from server: code=2200 [Invalid query] message=\"Unable to coerce '7/27/2012' to a formatted date (long)\""
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BowgBv6yyuCR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from datetime import datetime\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect('sales_data')\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "\n",
        "# Step 2: Load the CSV data using pandas\n",
        "csv_url = 'sales_100.csv'\n",
        "data = pd.read_csv(csv_url)\n",
        "\n",
        "# Step 3: Convert the 'Order Date' and 'Ship Date' columns to the correct format (YYYY-MM-DD)\n",
        "data['Order Date'] = pd.to_datetime(data['Order Date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
        "data['Ship Date'] = pd.to_datetime(data['Ship Date'], format='%m/%d/%Y').dt.strftime('%Y-%m-%d')\n",
        "\n",
        "# Step 4: Prepare the insert query\n",
        "insert_query = \"\"\"\n",
        "    INSERT INTO bronze_sales (Region, Country, Item_Type, Sales_Channel, Order_Priority, Order_Date,\n",
        "                              Order_ID, Ship_Date, Units_Sold, Unit_Price, Unit_Cost, Total_Revenue,\n",
        "                              Total_Cost, Total_Profit)\n",
        "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
        "\"\"\"\n",
        "\n",
        "# Step 5: Loop through the dataframe and insert each row into the Cassandra table\n",
        "for _, row in data.iterrows():\n",
        "    session.execute(insert_query, (\n",
        "        row['Region'], row['Country'], row['Item Type'], row['Sales Channel'], row['Order Priority'],\n",
        "        row['Order Date'], row['Order ID'], row['Ship Date'], row['UnitsSold'], row['UnitPrice'],\n",
        "        row['UnitCost'], row['TotalRevenue'], row['TotalCost'], row['TotalProfit']\n",
        "    ))\n",
        "\n",
        "print(\"Data inserted into the Bronze table.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W8vLt0mwyuSO",
        "outputId": "beba614f-5486-419c-f7fb-9536315cb579"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n",
            "Data inserted into the Bronze table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "from datetime import datetime\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect('sales_data')\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "\n",
        "\n",
        "# Step 2: Load the data from the Bronze table into a pandas DataFrame\n",
        "select_query = \"SELECT * FROM bronze_sales\"\n",
        "rows = session.execute(select_query)\n",
        "data = pd.DataFrame(list(rows))\n",
        "\n",
        "# Step 3: Inspect and clean the column names\n",
        "print(\"Column names in the DataFrame:\", data.columns)\n",
        "data.columns = data.columns.str.strip()  # Strip leading/trailing spaces\n",
        "print(\"Cleaned column names:\", data.columns)\n",
        "\n",
        "# Step 4: Data Cleaning and Transformation\n",
        "# Convert the 'Order_Date' and 'Ship_Date' columns to proper date format\n",
        "data['order_date'] = pd.to_datetime(data['order_date'], format='%Y-%m-%d', errors='coerce')\n",
        "data['ship_date'] = pd.to_datetime(data['ship_date'], format='%Y-%m-%d', errors='coerce')\n",
        "\n",
        "# Drop rows with missing or invalid values in critical columns\n",
        "data.dropna(subset=['order_date', 'ship_date', 'units_sold', 'unit_price', 'unit_cost'], inplace=True)\n",
        "\n",
        "# Step 5: Add the 'ProfitMargin' derived column (Profit / Revenue)\n",
        "data['profitmargin'] = data['total_profit'] / data['total_revenue']\n",
        "\n",
        "# Step 6: Prepare the insert query for the Silver table\n",
        "insert_query = \"\"\"\n",
        "    INSERT INTO silver_sales (region, country, item_type, sales_channel, order_priority, order_date,\n",
        "                              order_id, ship_date, units_sold, unit_price, unit_cost, total_revenue,\n",
        "                              total_cost, total_profit, profitmargin)\n",
        "    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s);\n",
        "\"\"\"\n",
        "\n",
        "# Step 7: Loop through the dataframe and insert each row into the Silver table\n",
        "for _, row in data.iterrows():\n",
        "    session.execute(insert_query, (\n",
        "        row['region'], row['country'], row['item_type'], row['sales_channel'], row['order_priority'],\n",
        "        row['order_date'].strftime('%Y-%m-%d'), row['order_id'], row['ship_date'].strftime('%Y-%m-%d'),\n",
        "        row['units_sold'], row['unit_price'], row['unit_cost'], row['total_revenue'], row['total_cost'],\n",
        "        row['total_profit'], row['profitmargin']  # Insert ProfitMargin here\n",
        "    ))\n",
        "\n",
        "print(\"Data inserted into the Silver table.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsD2D_yc2cZY",
        "outputId": "dc519a61-7c83-48d1-8b56-db036d885702"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n",
            "Column names in the DataFrame: Index(['order_id', 'country', 'item_type', 'order_date', 'order_priority',\n",
            "       'region', 'sales_channel', 'ship_date', 'total_cost', 'total_profit',\n",
            "       'total_revenue', 'unit_cost', 'unit_price', 'units_sold'],\n",
            "      dtype='object')\n",
            "Cleaned column names: Index(['order_id', 'country', 'item_type', 'order_date', 'order_priority',\n",
            "       'region', 'sales_channel', 'ship_date', 'total_cost', 'total_profit',\n",
            "       'total_revenue', 'unit_cost', 'unit_price', 'units_sold'],\n",
            "      dtype='object')\n",
            "Data inserted into the Silver table.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.auth import PlainTextAuthProvider\n",
        "\n",
        "# Establish a connection to your Astra Cassandra database\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect('sales_data')\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "\n",
        "# Fetch data from silver_sales table\n",
        "query = \"SELECT * FROM silver_sales\"\n",
        "rows = session.execute(query)\n",
        "df = pd.DataFrame(rows)\n",
        "\n",
        "# Aggregating data for gold_sales_region table\n",
        "gold_region_data = df.groupby('region').agg(\n",
        "    Total_Revenue=('total_revenue', 'sum'),\n",
        "    Total_Cost=('total_cost', 'sum'),\n",
        "    Total_Profit=('total_profit', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Inserting aggregated data into the gold_sales_region table\n",
        "for _, row in gold_region_data.iterrows():\n",
        "    insert_query = \"\"\"\n",
        "    INSERT INTO gold_sales_region (region, total_revenue, total_cost, total_profit)\n",
        "    VALUES (%s, %s, %s, %s)\n",
        "    \"\"\"\n",
        "    session.execute(insert_query, (row['region'], row['total_revenue'], row['total_cost'], row['total_profit']))\n",
        "\n",
        "# Aggregating data for gold_sales_item_type table\n",
        "gold_item_type_data = df.groupby('item_type').agg(\n",
        "    Total_Units_Sold=('units_sold', 'sum'),\n",
        "    Total_Revenue=('total_revenue', 'sum'),\n",
        "    Total_Profit=('total_profit', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Inserting aggregated data into the gold_sales_item_type table\n",
        "for _, row in gold_item_type_data.iterrows():\n",
        "    insert_query = \"\"\"\n",
        "    INSERT INTO gold_sales_item_type (item_type, total_units_sold, total_revenue, total_profit)\n",
        "    VALUES (%s, %s, %s, %s)\n",
        "    \"\"\"\n",
        "    session.execute(insert_query, (row['item_type'], row['total_units_sold'], row['total_revenue'], row['total_profit']))\n",
        "\n",
        "# Aggregating data for gold_sales_country table\n",
        "gold_country_data = df.groupby('country').agg(\n",
        "    Total_Revenue=('total_revenue', 'sum'),\n",
        "    Total_Profit=('total_profit', 'sum')\n",
        ").reset_index()\n",
        "\n",
        "# Inserting aggregated data into the gold_sales_country table\n",
        "for _, row in gold_country_data.iterrows():\n",
        "    insert_query = \"\"\"\n",
        "    INSERT INTO gold_sales_country (country, total_revenue, total_profit)\n",
        "    VALUES (%s, %s, %s)\n",
        "    \"\"\"\n",
        "    session.execute(insert_query, (row['country'], row['total_revenue'], row['total_profit']))\n",
        "\n",
        "print(\"Data successfully inserted into gold tables.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 625
        },
        "id": "azw9oNhR3rZk",
        "outputId": "d009b367-1c40-4f14-d33e-d9e8b6d8c82c"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:00958fd0-af98-391f-9f51-7e3fe763da5c. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyError",
          "evalue": "'total_revenue'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3804\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3805\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcasted_key\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3806\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mindex.pyx\u001b[0m in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/hashtable_class_helper.pxi\u001b[0m in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_revenue'",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-37-df0d5dbe78c2>\u001b[0m in \u001b[0;36m<cell line: 41>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mVALUES\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \"\"\"\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minsert_query\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'region'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_revenue'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_cost'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrow\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'total_profit'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m \u001b[0;31m# Aggregating data for gold_sales_item_type table\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   1119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1120\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mkey_is_scalar\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1121\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_value\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1122\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m         \u001b[0;31m# Convert generator to list before going through hashable part\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/series.py\u001b[0m in \u001b[0;36m_get_value\u001b[0;34m(self, label, takeable)\u001b[0m\n\u001b[1;32m   1235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1236\u001b[0m         \u001b[0;31m# Similar to Index.get_value, but we do not fall back to positional\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1237\u001b[0;31m         \u001b[0mloc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_loc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1239\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/pandas/core/indexes/base.py\u001b[0m in \u001b[0;36mget_loc\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m   3810\u001b[0m             ):\n\u001b[1;32m   3811\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0mInvalidIndexError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3812\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3813\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3814\u001b[0m             \u001b[0;31m# If we have a listlike key, _check_indexing_error will raise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyError\u001b[0m: 'total_revenue'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "-Advt_KTK_qF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eC3VI7i-K_sq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from cassandra.cluster import Cluster\n",
        "from cassandra.query import SimpleStatement\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect('sales_data')\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "\n",
        "# Define the path to the CSV file\n",
        "csv_file_path = 'sales_100.csv'  # Change this to your actual file path\n",
        "\n",
        "# Prepare the insert statement\n",
        "insert_statement = \"\"\"\n",
        "    INSERT INTO gold_sales_region (region, total_cost, total_profit, total_revenue)\n",
        "    VALUES (?, ?, ?, ?)\n",
        "\"\"\"\n",
        "\n",
        "# Use a prepared statement for better performance and security\n",
        "prepared = session.prepare(insert_statement)\n",
        "\n",
        "# Open the CSV file and read the data\n",
        "with open(csv_file_path, 'r') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "\n",
        "    # Iterate through the rows in the CSV file\n",
        "    for row in csv_reader:\n",
        "        # Prepare data tuple for insertion\n",
        "        region = row['Region']\n",
        "        total_cost = float(row['TotalCost'])\n",
        "        total_profit = float(row['TotalProfit'])\n",
        "        total_revenue = float(row['TotalRevenue'])\n",
        "\n",
        "        # Execute the insert statement\n",
        "        session.execute(prepared, (region, total_cost, total_profit, total_revenue))\n",
        "\n",
        "# Close the session and connection\n",
        "cluster.shutdown()\n",
        "\n",
        "print(\"Data inserted successfully into gold_sales_region.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DF01OsXLK_vi",
        "outputId": "69e64621-cf0c-4bfb-9482-daac8d05415e"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:9e3a5bee-3d95-3bf7-90f5-09bd2177324b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:9e3a5bee-3d95-3bf7-90f5-09bd2177324b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:9e3a5bee-3d95-3bf7-90f5-09bd2177324b. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n",
            "Data inserted successfully into gold_sales_region.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from cassandra.cluster import Cluster\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect('sales_data')\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "\n",
        "# Define the path to the CSV file\n",
        "csv_file_path = 'sales_100.csv'  # Change this to your actual file path\n",
        "\n",
        "# Prepare the insert statement with '?' placeholders\n",
        "insert_statement = \"\"\"\n",
        "    INSERT INTO gold_sales_item_type (item_type, total_profit, total_revenue)\n",
        "    VALUES (?, ?, ?)\n",
        "\"\"\"\n",
        "\n",
        "# Use a prepared statement for better performance and security\n",
        "prepared = session.prepare(insert_statement)\n",
        "\n",
        "# Open the CSV file and read the data\n",
        "with open(csv_file_path, 'r') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "\n",
        "    # Iterate through the rows in the CSV file\n",
        "    for row in csv_reader:\n",
        "        # Extract relevant columns from the CSV\n",
        "        item_type = row['Item Type']\n",
        "        total_profit = float(row['TotalProfit'])\n",
        "        total_revenue = float(row['TotalRevenue'])\n",
        "\n",
        "        # Execute the insert statement\n",
        "        session.execute(prepared, (item_type, total_profit, total_revenue))\n",
        "\n",
        "# Close the session and connection\n",
        "cluster.shutdown()\n",
        "\n",
        "print(\"Data inserted successfully into gold_sales_item_type.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BX3AmbZ-MdNy",
        "outputId": "74aa1022-324d-4cfc-bd57-e629700adc46"
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:190dafab-6970-3a67-a21c-1226360de7dc. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:190dafab-6970-3a67-a21c-1226360de7dc. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:190dafab-6970-3a67-a21c-1226360de7dc. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n",
            "Data inserted successfully into gold_sales_item_type.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from cassandra.cluster import Cluster\n",
        "\n",
        "cloud_config= {\n",
        "  'secure_connect_bundle': 'secure-connect-assignment.zip'\n",
        "}\n",
        "\n",
        "# This token JSON file is autogenerated when you download your token,\n",
        "# if yours is different update the file name below\n",
        "with open(\"assignment-token.json\") as f:\n",
        "    secrets = json.load(f)\n",
        "\n",
        "CLIENT_ID = secrets[\"clientId\"]\n",
        "CLIENT_SECRET = secrets[\"secret\"]\n",
        "\n",
        "auth_provider = PlainTextAuthProvider(CLIENT_ID, CLIENT_SECRET)\n",
        "cluster = Cluster(cloud=cloud_config, auth_provider=auth_provider)\n",
        "session = cluster.connect('sales_data')\n",
        "\n",
        "row = session.execute(\"select release_version from system.local\").one()\n",
        "if row:\n",
        "  print(row[0])\n",
        "else:\n",
        "  print(\"An error occurred.\")\n",
        "# Define the path to the CSV file\n",
        "csv_file_path = 'sales_100.csv'  # Change this to your actual file path\n",
        "\n",
        "# Prepare the insert statement with '?' placeholders\n",
        "insert_statement = \"\"\"\n",
        "    INSERT INTO gold_sales_country (country, total_profit, total_revenue)\n",
        "    VALUES (?, ?, ?)\n",
        "\"\"\"\n",
        "\n",
        "# Use a prepared statement for better performance and security\n",
        "prepared = session.prepare(insert_statement)\n",
        "\n",
        "# Open the CSV file and read the data\n",
        "with open(csv_file_path, 'r') as file:\n",
        "    csv_reader = csv.DictReader(file)\n",
        "\n",
        "    # Iterate through the rows in the CSV file\n",
        "    for row in csv_reader:\n",
        "        # Extract relevant columns from the CSV\n",
        "        country = row['Country']\n",
        "        total_profit = float(row['TotalProfit'])\n",
        "        total_revenue = float(row['TotalRevenue'])\n",
        "\n",
        "        # Execute the insert statement\n",
        "        session.execute(prepared, (country, total_profit, total_revenue))\n",
        "\n",
        "# Close the session and connection\n",
        "cluster.shutdown()\n",
        "\n",
        "print(\"Data inserted successfully into gold_sales_country.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_PBQN601OOh0",
        "outputId": "bcc5340e-8d80-4370-a763-67d09cdd8139"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:cassandra.cluster:Downgrading core protocol version from 66 to 65 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 65 to 5 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n",
            "WARNING:cassandra.cluster:Downgrading core protocol version from 5 to 4 for 80a27a17-065f-4d06-a6e3-520269c2411e-us-east1.db.astra.datastax.com:29042:0669df0f-031f-383e-b452-67a9679bbc6a. To avoid this, it is best practice to explicitly set Cluster(protocol_version) to the version supported by your cluster. http://datastax.github.io/python-driver/api/cassandra/cluster.html#cassandra.cluster.Cluster.protocol_version\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "4.0.0.6816\n",
            "Data inserted successfully into gold_sales_country.\n"
          ]
        }
      ]
    }
  ]
}